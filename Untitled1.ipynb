{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Untitled1.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"12ZMhew1Xkef","colab_type":"code","colab":{},"outputId":"4b5e4180-5dba-4c4b-84e9-d92fa7638812"},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting numpy==1.16.1\n","  Downloading https://files.pythonhosted.org/packages/41/b8/3a6b07352c2542ca1c89be7583e7ca07bf513895b6ac59ae008054f326b1/numpy-1.16.1-cp37-cp37m-win_amd64.whl (11.9MB)\n","Installing collected packages: numpy\n","  Found existing installation: numpy 1.16.5\n","    Uninstalling numpy-1.16.5:\n","      Successfully uninstalled numpy-1.16.5\n"],"name":"stdout"},{"output_type":"stream","text":["ERROR: Could not install packages due to an EnvironmentError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\users\\\\user\\\\anaconda3\\\\envs\\\\tenpy\\\\lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp37-win_amd64.pyd'\n","Consider using the `--user` option or check the permissions.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"sP2rFpm2Xker","colab_type":"code","colab":{}},"source":["from numpy import load\n","import numpy as np\n","\n","data1 = load('angel.npy')\n","data2 = load('banana.npy')\n","data_array = [data1[0:80000], data2[0:80000]]\n","input_data = np.concatenate((data1[0:80000], data2[0:80000]),axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"moZbhE8UXke1","colab_type":"code","colab":{},"outputId":"8d5aadb5-0bb4-4ac2-86e3-bf865d2c32f8"},"source":["len(data_array[0])\n","name=0\n","for i in range(len(data_array[0])):\n","    name +=1\n","print(name)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["149736\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7K6S4LltXke-","colab_type":"code","colab":{},"outputId":"a284159b-37e1-4d38-bb7f-5555072e5345"},"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from numpy import array\n","\n","train_dir = 'C:/Users/USER/python/Untitled Folder/trainset'\n","train_folder = array(os.listdir(train_dir))\n","print(train_folder)\n","\n","\n","label_data = []\n","t_label_data = []\n","\n","label_encoder = LabelEncoder()\n","int_encoded = label_encoder.fit_transform(train_folder)\n","print(int_encoded)\n","onehot_encoder = OneHotEncoder(sparse=False)\n","int_encoded = int_encoded.reshape(len(int_encoded),1)\n","onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n","print(onehot_encoded)\n","for i in range(2):\n","    for j in range(len(data_array[i])):\n","        label_data.append([np.array(onehot_encoded[i])])\n","np.save('input_data.npy', input_data)\n","np.save('label_data.npy', label_data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['angel' 'banana']\n","[0 1]\n","[[1. 0.]\n"," [0. 1.]]\n"],"name":"stdout"},{"output_type":"stream","text":["C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VjBl6ViuXkfL","colab_type":"code","colab":{},"outputId":"ee37f64f-7093-4180-dc8d-c25547049a24"},"source":["print(len(input_data), len(label_data))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["160000 160000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YPM2LjZrXkfW","colab_type":"code","colab":{}},"source":["data_array = [data1[80000:100000], data2[80000:100000]]\n","t_input_data = np.concatenate((data1[80000:100000], data2[80000:100000]),axis=0)\n","t_label_data = []\n","for i in range(2):\n","    for j in range(len(data_array[i])):\n","        t_label_data.append([np.array(onehot_encoded[i])])\n","np.save('t_input_data.npy', t_input_data)\n","np.save('t_label_data.npy', t_label_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxRcuVUaXkfe","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","tf.reset_default_graph ()  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"btQJP7ZoXkfs","colab_type":"code","colab":{},"outputId":"a2813249-982b-4f88-d174-582aef9b444d"},"source":["import tensorflow as tf\n","# hyper parameters\n","\n","learning_rate = 0.001\n","\n","# input place holders\n","X = tf.placeholder(tf.float32, [None, 784])\n","X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n","Y = tf.placeholder(tf.float32, [None, 2])\n"," \n","W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n","L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n","L1 = tf.nn.relu(L1)\n","L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n"," \n","W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n","L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n","L2 = tf.nn.relu(L2)\n","L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n"," \n","L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n","W3 = tf.get_variable(\"W4\", shape=[7 * 7 * 64, 2], initializer=tf.contrib.layers.xavier_initializer())\n","b = tf.Variable(tf.random_normal([2]))\n","logits = tf.matmul(L2_flat, W6) + b\n","\n","# define cost/loss &amp;amp;amp; optimizer\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"," \n","training_epochs = 15\n","batch_size = 100\n"," \n","# initialize\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n"," \n","# train my model\n","print('Learning started. It takes sometime.')\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","    total_batch = int(len(input_data) / batch_size)\n"," \n","    for i in range(total_batch):\n","        start = ((0 + 1) * batch_size) - batch_size\n","        print(start)\n","        end = ((i + 1) * batch_size)\n","        batch_xs = input_data[start:end]\n","        print(batch_xs, len(batch_xs))\n","        batch_ys = label_data[start:end]\n","        print(batch_ys, len(batch_ys))\n","        feed_dict = {X: batch_xs, Y: batch_ys}\n","        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n","        avg_cost += c / total_batch\n"," \n","    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n"," \n","print('Learning Finished!')\n","\n","# Test model and check accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","print('Accuracy:', sess.run(accuracy, feed_dict={\n","      X: t_input_data, Y: t_label_data}))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Variable W4 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1608, in variable_v2\n    shared_name=shared_name, name=name)\n","traceback":["\u001b[1;31m--------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m       Traceback (most recent call last)","\u001b[1;32m<ipython-input-63-fed7b0e32f7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mL2_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mW3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL2_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW6\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1494\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1237\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[1;32m~\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    560\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[1;32m~\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    512\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     synchronization, aggregation, trainable = (\n","\u001b[1;32m~\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[1;32m--> 864\u001b[1;33m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    865\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Variable W4 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\USER\\Anaconda3\\envs\\tenpy\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1608, in variable_v2\n    shared_name=shared_name, name=name)\n"]}]}]}